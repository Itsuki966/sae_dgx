"""
ä»‹å…¥å®Ÿé¨“ã«ãŠã‘ã‚‹æ´»æ€§åŒ–çµ±è¨ˆã®åˆ†æä¾‹

ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã§ã¯ã€ä»‹å…¥å®Ÿé¨“ã§åé›†ã•ã‚ŒãŸæ´»æ€§åŒ–çµ±è¨ˆã‚’åˆ†æã™ã‚‹æ–¹æ³•ã‚’ç¤ºã—ã¾ã™ã€‚
"""

import json
from pathlib import Path
from typing import Dict, List
import pandas as pd


def load_intervention_results(filepath: str) -> Dict:
    """ä»‹å…¥å®Ÿé¨“ã®çµæœã‚’èª­ã¿è¾¼ã¿"""
    with open(filepath, 'r', encoding='utf-8') as f:
        return json.load(f)


def analyze_feature_activations(results: Dict) -> pd.DataFrame:
    """
    ç‰¹å¾´é‡ã”ã¨ã®æ´»æ€§åŒ–çµ±è¨ˆã‚’DataFrameã«ã¾ã¨ã‚ã‚‹
    
    Returns:
        å„ç‰¹å¾´é‡ã®çµ±è¨ˆæƒ…å ±ã‚’å«ã‚€DataFrame
    """
    activation_summary = results.get('activation_summary', {})
    per_feature = activation_summary.get('per_feature_summary', {})
    
    rows = []
    for feature_id, stats in per_feature.items():
        rows.append({
            'feature_id': int(feature_id),
            'avg_mean_activation': stats['avg_mean_activation'],
            'avg_max_activation': stats['avg_max_activation'],
            'avg_sparsity': stats['avg_sparsity'],
            'num_prompts': stats['num_prompts']
        })
    
    df = pd.DataFrame(rows)
    df = df.sort_values('avg_mean_activation', ascending=False)
    return df


def analyze_per_prompt_activations(results: Dict) -> pd.DataFrame:
    """
    ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã”ã¨ã®æ´»æ€§åŒ–çµ±è¨ˆã‚’DataFrameã«ã¾ã¨ã‚ã‚‹
    
    Returns:
        å„ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®çµ±è¨ˆæƒ…å ±ã‚’å«ã‚€DataFrame
    """
    rows = []
    
    for result in results['results']:
        question_id = result['question_id']
        dataset = result['dataset']
        
        for variation in result['variations']:
            template_type = variation['template_type']
            activation_stats = variation['metadata'].get('activation_stats', {})
            overall = activation_stats.get('overall', {})
            
            rows.append({
                'question_id': question_id,
                'dataset': dataset,
                'template_type': template_type,
                'mean_activation': overall.get('mean_across_features', 0.0),
                'max_activation': overall.get('max_across_features', 0.0),
                'total_active_features': overall.get('total_active_features', 0),
                'num_intervention_features': overall.get('num_intervention_features', 0)
            })
    
    return pd.DataFrame(rows)


def find_most_active_features(results: Dict, top_k: int = 10) -> List[Dict]:
    """
    æœ€ã‚‚æ´»æ€§åŒ–ã—ãŸç‰¹å¾´é‡ã‚’ãƒˆãƒƒãƒ—Kå€‹å–å¾—
    
    Args:
        results: ä»‹å…¥å®Ÿé¨“ã®çµæœ
        top_k: ä¸Šä½ä½•å€‹ã‚’å–å¾—ã™ã‚‹ã‹
    
    Returns:
        ä¸Šä½Kå€‹ã®ç‰¹å¾´é‡æƒ…å ±
    """
    df = analyze_feature_activations(results)
    top_features = df.head(top_k)
    
    return top_features.to_dict('records')


def compare_template_activations(results: Dict) -> pd.DataFrame:
    """
    ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚¿ã‚¤ãƒ—ã”ã¨ã®æ´»æ€§åŒ–ã‚’æ¯”è¼ƒ
    
    Returns:
        ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚¿ã‚¤ãƒ—åˆ¥ã®å¹³å‡çµ±è¨ˆ
    """
    df = analyze_per_prompt_activations(results)
    
    comparison = df.groupby('template_type').agg({
        'mean_activation': ['mean', 'std'],
        'max_activation': ['mean', 'std'],
        'total_active_features': ['mean', 'std']
    }).round(3)
    
    return comparison


def print_activation_summary(results: Dict):
    """æ´»æ€§åŒ–çµ±è¨ˆã®ã‚µãƒãƒªã‚’è¡¨ç¤º"""
    activation_summary = results.get('activation_summary', {})
    
    print("=" * 60)
    print("æ´»æ€§åŒ–çµ±è¨ˆã‚µãƒãƒª")
    print("=" * 60)
    print(f"è³ªå•æ•°: {activation_summary.get('num_questions', 0)}")
    print(f"ç·ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ•°: {activation_summary.get('num_prompts', 0)}")
    print(f"ä»‹å…¥ç‰¹å¾´é‡æ•°: {activation_summary.get('num_intervention_features', 0)}")
    print()
    
    # æœ€ã‚‚æ´»æ€§åŒ–ã—ãŸç‰¹å¾´é‡ãƒˆãƒƒãƒ—10
    print("æœ€ã‚‚æ´»æ€§åŒ–ã—ãŸç‰¹å¾´é‡ (Top 10):")
    print("-" * 60)
    
    top_features = find_most_active_features(results, top_k=10)
    for i, feature in enumerate(top_features, 1):
        print(f"{i}. Feature {feature['feature_id']}:")
        print(f"   å¹³å‡æ´»æ€§å€¤: {feature['avg_mean_activation']:.3f}")
        print(f"   æœ€å¤§æ´»æ€§å€¤: {feature['avg_max_activation']:.3f}")
        print(f"   ã‚¹ãƒ‘ãƒ¼ã‚¹æ€§: {feature['avg_sparsity']:.3f}")
    
    print()
    
    # ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆåˆ¥æ¯”è¼ƒ
    print("ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚¿ã‚¤ãƒ—åˆ¥ã®æ´»æ€§åŒ–æ¯”è¼ƒ:")
    print("-" * 60)
    comparison = compare_template_activations(results)
    print(comparison)


def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•° - ä½¿ç”¨ä¾‹"""
    
    # çµæœãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã‚’æŒ‡å®š
    # ä¾‹: results/intervention/intervention_gemma-2-9b-it_20251208_120000_0-99.json
    results_dir = Path("results/intervention")
    
    # æœ€æ–°ã®çµæœãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—
    result_files = list(results_dir.glob("intervention_*.json"))
    if not result_files:
        print("ä»‹å…¥å®Ÿé¨“ã®çµæœãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        return
    
    latest_file = max(result_files, key=lambda p: p.stat().st_mtime)
    print(f"ğŸ“‚ åˆ†æå¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«: {latest_file.name}\n")
    
    # çµæœã‚’èª­ã¿è¾¼ã¿
    results = load_intervention_results(str(latest_file))
    
    # ã‚µãƒãƒªã‚’è¡¨ç¤º
    print_activation_summary(results)
    
    # DataFrameã¨ã—ã¦è©³ç´°åˆ†æ
    print("\n" + "=" * 60)
    print("è©³ç´°åˆ†æ (DataFrame)")
    print("=" * 60)
    
    # ç‰¹å¾´é‡ã”ã¨ã®çµ±è¨ˆ
    df_features = analyze_feature_activations(results)
    print("\nç‰¹å¾´é‡ã”ã¨ã®çµ±è¨ˆ (ä¸Šä½5ã¤):")
    print(df_features.head())
    
    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã”ã¨ã®çµ±è¨ˆ
    df_prompts = analyze_per_prompt_activations(results)
    print("\nãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã”ã¨ã®çµ±è¨ˆ (æœ€åˆã®5ã¤):")
    print(df_prompts.head())
    
    # CSVã«ä¿å­˜
    output_dir = Path("results/intervention/analysis")
    output_dir.mkdir(parents=True, exist_ok=True)
    
    features_csv = output_dir / f"feature_activations_{latest_file.stem}.csv"
    prompts_csv = output_dir / f"prompt_activations_{latest_file.stem}.csv"
    
    df_features.to_csv(features_csv, index=False)
    df_prompts.to_csv(prompts_csv, index=False)
    
    print(f"\nğŸ’¾ åˆ†æçµæœã‚’ä¿å­˜:")
    print(f"   {features_csv}")
    print(f"   {prompts_csv}")


if __name__ == "__main__":
    main()
