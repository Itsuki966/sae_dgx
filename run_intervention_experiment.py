"""
ä»‹å…¥å®Ÿé¨“å®Ÿè¡Œã‚¹ã‚¯ãƒªãƒ—ãƒˆ

intervention_experiment.ipynb ã¨åŒã˜å‡¦ç†ã‚’è¡Œã†ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³ã‚¹ã‚¯ãƒªãƒ—ãƒˆã€‚
ç‰¹å®šã•ã‚ŒãŸSAEç‰¹å¾´é‡ã«å¯¾ã—ã¦Geometric Subtractionã«ã‚ˆã‚‹ä»‹å…¥ã‚’è¡Œã„ã€
Baseline vs Intervention ã®æ¯”è¼ƒå®Ÿé¨“ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚

Usage:
    # CSVã‹ã‚‰ç‰¹å¾´é‡IDã‚’èª­ã¿è¾¼ã‚“ã§å®Ÿé¨“ã‚’å®Ÿè¡Œ
    python run_intervention_experiment.py --features-csv results/intervention/candidates/intervention_candidates_20251211_193847.csv
    
    # ç‰¹å®šã®ç¯„å›²ã§å®Ÿé¨“ã‚’å®Ÿè¡Œ
    python run_intervention_experiment.py --features-csv results/intervention/candidates/intervention_candidates_20251211_193847.csv --start-index 100 --end-index 200
    
    # ã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚ºã‚’æŒ‡å®š
    python run_intervention_experiment.py --features-csv results/intervention/candidates/intervention_candidates_20251211_193847.csv --sample-size 10
    
    # ç‰¹å¾´é‡IDã‚’ç›´æ¥æŒ‡å®š
    python run_intervention_experiment.py --features 123,456,789 --sample-size 5
"""

import argparse
import json
import sys
import torch
import pandas as pd
from pathlib import Path
from typing import List, Optional

from intervention_runner import InterventionRunner
from config import INTERVENTION_GEMMA2_9B_IT_CONFIG


def load_feature_ids_from_csv(csv_path: str) -> List[int]:
    """
    CSVãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ç‰¹å¾´é‡IDãƒªã‚¹ãƒˆã‚’èª­ã¿è¾¼ã‚€
    
    Args:
        csv_path: CSVãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
        
    Returns:
        ç‰¹å¾´é‡IDã®ãƒªã‚¹ãƒˆ
    """
    df = pd.read_csv(csv_path)
    
    # 'feature_index' ã¾ãŸã¯ 'feature_id' ã‚«ãƒ©ãƒ ã‹ã‚‰èª­ã¿è¾¼ã¿
    if 'feature_index' in df.columns:
        feature_ids = list(df['feature_index'])
    elif 'feature_id' in df.columns:
        feature_ids = list(df['feature_id'])
    else:
        raise ValueError(f"CSV file must contain 'feature_index' or 'feature_id' column. Found columns: {df.columns.tolist()}")
    
    return feature_ids


def load_feature_ids_from_json(json_path: str) -> List[int]:
    """
    JSONãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ç‰¹å¾´é‡IDãƒªã‚¹ãƒˆã‚’èª­ã¿è¾¼ã‚€
    
    Args:
        json_path: JSONãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
        
    Returns:
        ç‰¹å¾´é‡IDã®ãƒªã‚¹ãƒˆ
    """
    with open(json_path, 'r') as f:
        data = json.load(f)
    
    # æ§˜ã€…ãªå½¢å¼ã«å¯¾å¿œ
    if isinstance(data, list):
        return data
    elif 'top_k_features' in data:
        return data['top_k_features']
    elif 'feature_ids' in data:
        return data['feature_ids']
    elif 'intervention_features' in data:
        return data['intervention_features']
    else:
        raise ValueError(f"JSON file must contain feature IDs. Found keys: {data.keys()}")


def print_gpu_info():
    """GPUæƒ…å ±ã‚’è¡¨ç¤º"""
    if torch.cuda.is_available():
        print(f"ğŸ® GPU available: {torch.cuda.get_device_name(0)}")
        print(f"ğŸ’¾ GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB")
    else:
        print("âš ï¸ No GPU available. Using CPU (this will be slow)")


def print_configuration(config, feature_ids: List[int]):
    """å®Ÿé¨“è¨­å®šã‚’è¡¨ç¤º"""
    print("\n" + "="*60)
    print("âš™ï¸  Experiment Configuration")
    print("="*60)
    print(f"Model: {config.model.name}")
    print(f"SAE: {config.model.sae_release}/{config.model.sae_id}")
    print(f"Hook: {config.model.hook_name}")
    print(f"Dataset: {config.data.dataset_path}")
    print(f"Sample size: {config.data.sample_size}")
    print(f"Max new tokens: {config.generation.max_new_tokens}")
    print(f"Temperature: {config.generation.temperature}")
    print(f"Do sample: {config.generation.do_sample}")
    print(f"Number of intervention features: {len(feature_ids)}")
    print(f"Feature IDs (first 5): {feature_ids[:5]}...")
    print("="*60 + "\n")


def analyze_results(results_path: str):
    """
    å®Ÿé¨“çµæœã‚’åˆ†æã—ã¦è¡¨ç¤º
    
    Args:
        results_path: çµæœãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
    """
    with open(results_path, 'r', encoding='utf-8') as f:
        results = json.load(f)
    
    print("\n" + "="*60)
    print("ğŸ“Š Experiment Results Summary")
    print("="*60)
    print(f"Model: {results['metadata']['model_name']}")
    print(f"Intervention method: {results['metadata']['intervention_method']}")
    print(f"Number of intervention features: {results['metadata']['num_intervention_features']}")
    print(f"Total questions processed: {results['metadata']['num_questions']}")
    print(f"Question ID range: {results['metadata']['question_id_range']['start']} - {results['metadata']['question_id_range']['end']}")
    print(f"Timestamp: {results['metadata']['timestamp']}")
    print("="*60)
    
    # æ´»æ€§åŒ–ã‚µãƒãƒªã®è¡¨ç¤º
    if 'activation_summary' in results:
        act_summary = results['activation_summary']
        print("\nğŸ“ˆ Activation Summary:")
        print(f"  Total prompts processed: {act_summary['num_prompts']}")
        print(f"  Number of intervention features: {act_summary['num_intervention_features']}")
    
    # ã‚µãƒ³ãƒ—ãƒ«çµæœã®è¡¨ç¤º
    if results['results']:
        first_question = results['results'][0]
        
        print("\nğŸ“ Sample Result (Question 1):")
        print("="*60)
        print(f"Dataset: {first_question['dataset']}")
        print(f"Base text: {first_question['base_text'][:100]}...")
        print(f"Number of variations: {len(first_question['variations'])}")
        
        # æœ€åˆã®ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ã®è©³ç´°
        first_variation = first_question['variations'][0]
        print(f"\n--- Variation 1: {first_variation['template']} ---")
        print(f"Prompt: {first_variation['prompt'][:150]}...")
        print(f"\nBaseline Response:")
        print(f"  {first_variation['baseline_response']}")
        print(f"\nIntervention Response:")
        print(f"  {first_variation['intervention_response']}")
        print("="*60)
    
    # å¿œç­”å¤‰åŒ–ç‡ã®åˆ†æ
    total_variations = 0
    changed_variations = 0
    
    for question in results['results']:
        for variation in question['variations']:
            total_variations += 1
            baseline = variation['baseline_response'].strip()
            intervention = variation['intervention_response'].strip()
            
            if baseline != intervention:
                changed_variations += 1
    
    change_rate = (changed_variations / total_variations * 100) if total_variations > 0 else 0
    
    print("\nğŸ“ˆ Response Change Analysis:")
    print("="*60)
    print(f"Total variations processed: {total_variations}")
    print(f"Variations with changed response: {changed_variations}")
    print(f"Change rate: {change_rate:.2f}%")
    print("="*60)
    
    print("\nâ„¹ï¸  Next steps:")
    print("  1. Use GPT-4o to evaluate sycophancy flags for baseline vs intervention")
    print("  2. Use GPT-4o to rate naturalness scores (1-5 scale)")
    print("  3. Perform McNemar's test for statistical significance")
    print("  4. Analyze qualitative changes in response content")


def main():
    parser = argparse.ArgumentParser(
        description="ä»‹å…¥å®Ÿé¨“ã‚’å®Ÿè¡Œã—ã¦ã€ç‰¹å®šã®SAEç‰¹å¾´é‡ã®åŠ¹æœã‚’è©•ä¾¡ã—ã¾ã™ã€‚",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  # CSVã‹ã‚‰ç‰¹å¾´é‡IDã‚’èª­ã¿è¾¼ã‚“ã§å®Ÿé¨“ã‚’å®Ÿè¡Œ
  python run_intervention_experiment.py --features-csv results/intervention/candidates/intervention_candidates_20251211_193847.csv
  
  # ç‰¹å®šã®ç¯„å›²ã§å®Ÿé¨“ã‚’å®Ÿè¡Œ
  python run_intervention_experiment.py --features-csv results/intervention/candidates/intervention_candidates_20251211_193847.csv --start-index 100 --end-index 200
  
  # ã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚ºã‚’æŒ‡å®š
  python run_intervention_experiment.py --features-csv results/intervention/candidates/intervention_candidates_20251211_193847.csv --sample-size 10
  
  # ç‰¹å¾´é‡IDã‚’ç›´æ¥æŒ‡å®š
  python run_intervention_experiment.py --features 123,456,789 --sample-size 5
        """
    )
    
    # ç‰¹å¾´é‡IDæŒ‡å®šã‚ªãƒ—ã‚·ãƒ§ãƒ³
    feature_group = parser.add_mutually_exclusive_group(required=True)
    feature_group.add_argument(
        '--features-csv',
        type=str,
        help='ç‰¹å¾´é‡IDã‚’å«ã‚€CSVãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹'
    )
    feature_group.add_argument(
        '--features-json',
        type=str,
        help='ç‰¹å¾´é‡IDã‚’å«ã‚€JSONãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹'
    )
    feature_group.add_argument(
        '--features',
        type=str,
        help='ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šã®ç‰¹å¾´é‡IDãƒªã‚¹ãƒˆï¼ˆä¾‹: 123,456,789ï¼‰'
    )
    
    # å®Ÿé¨“ç¯„å›²æŒ‡å®šã‚ªãƒ—ã‚·ãƒ§ãƒ³
    parser.add_argument(
        '--sample-size',
        type=int,
        default=None,
        help='å‡¦ç†ã™ã‚‹ã‚µãƒ³ãƒ—ãƒ«æ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: configã®è¨­å®šã‚’ä½¿ç”¨ï¼‰'
    )
    parser.add_argument(
        '--start-index',
        type=int,
        default=None,
        help='é–‹å§‹ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ï¼ˆ0-basedï¼‰'
    )
    parser.add_argument(
        '--end-index',
        type=int,
        default=None,
        help='çµ‚äº†ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ï¼ˆ0-basedï¼‰'
    )
    
    # ãã®ä»–ã®ã‚ªãƒ—ã‚·ãƒ§ãƒ³
    parser.add_argument(
        '--config',
        type=str,
        default='INTERVENTION_GEMMA2_9B_IT_CONFIG',
        help='ä½¿ç”¨ã™ã‚‹è¨­å®šåï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: INTERVENTION_GEMMA2_9B_IT_CONFIGï¼‰'
    )
    parser.add_argument(
        '--no-analysis',
        action='store_true',
        help='å®Ÿé¨“å®Ÿè¡Œå¾Œã®çµæœåˆ†æã‚’ã‚¹ã‚­ãƒƒãƒ—'
    )
    parser.add_argument(
        '--output-dir',
        type=str,
        default=None,
        help='çµæœã®å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: results/interventionï¼‰'
    )
    
    args = parser.parse_args()
    
    # ç‰¹å¾´é‡IDã®èª­ã¿è¾¼ã¿
    print("ğŸ“‚ Loading intervention feature IDs...")
    if args.features_csv:
        feature_ids = load_feature_ids_from_csv(args.features_csv)
        print(f"âœ… Loaded {len(feature_ids)} features from CSV: {args.features_csv}")
    elif args.features_json:
        feature_ids = load_feature_ids_from_json(args.features_json)
        print(f"âœ… Loaded {len(feature_ids)} features from JSON: {args.features_json}")
    else:
        feature_ids = [int(x.strip()) for x in args.features.split(',')]
        print(f"âœ… Using {len(feature_ids)} features from command line")
    
    # GPUæƒ…å ±ã®è¡¨ç¤º
    print_gpu_info()
    
    # è¨­å®šã®èª­ã¿è¾¼ã¿
    print(f"\nğŸ“‹ Loading configuration: {args.config}")
    import config as config_module
    if not hasattr(config_module, args.config):
        print(f"âŒ Error: Configuration '{args.config}' not found in config.py")
        sys.exit(1)
    
    experiment_config = getattr(config_module, args.config)
    
    # ã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚ºã®ä¸Šæ›¸ã
    if args.sample_size is not None:
        experiment_config.data.sample_size = args.sample_size
    
    # è¨­å®šã®è¡¨ç¤º
    print_configuration(experiment_config, feature_ids)
    
    # InterventionRunnerã®åˆæœŸåŒ–
    print("ğŸ”§ Initializing InterventionRunner...")
    runner = InterventionRunner(
        config=experiment_config,
        intervention_feature_ids=feature_ids
    )
    print("âœ… InterventionRunner initialized")
    
    # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®è¨­å®š
    if args.output_dir:
        runner.results_dir = Path(args.output_dir)
        runner.results_dir.mkdir(parents=True, exist_ok=True)
    
    # å®Ÿé¨“ã®å®Ÿè¡Œ
    print("\nğŸš€ Starting intervention experiment...")
    try:
        output_path = runner.run_complete_experiment(
            sample_size=args.sample_size,
            start_index=args.start_index,
            end_index=args.end_index
        )
        print(f"\nâœ… Experiment completed successfully!")
        print(f"ğŸ“ Results saved to: {output_path}")
        
        # çµæœã®åˆ†æ
        if not args.no_analysis:
            analyze_results(output_path)
        
        return 0
        
    except KeyboardInterrupt:
        print("\nâš ï¸ Experiment interrupted by user")
        return 1
    except Exception as e:
        print(f"\nâŒ Error during experiment: {e}")
        import traceback
        traceback.print_exc()
        return 1


if __name__ == "__main__":
    sys.exit(main())
